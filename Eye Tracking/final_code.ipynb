{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import these libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from math import hypot\n",
    "import math\n",
    "import pyautogui\n",
    "from imutils import face_utils\n",
    "import imutils\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pyautogui.FAILSAFE = False\n",
    "Scroll = False\n",
    "pTime = 0\n",
    "\n",
    "# variables for frame rate.\n",
    "frame_counter = 0\n",
    "start_time = time.time()\n",
    "FPS = 0\n",
    "\n",
    "# f1 = open('time.txt', 'w')\n",
    "# f2 = open('right.txt', 'w')\n",
    "# f3 = open('left.txt', 'w')\n",
    "# f4 = open('net_blink_ratio.txt', 'w')\n",
    "\n",
    "# f5 = open(' gaze_ratio_lefteye_LR.txt', 'w')\n",
    "# f6 = open('gaze_ratio_righteye_LR.txt', 'w')\n",
    "# f7 = open('net_gaze_ratio_LR.txt', 'w')\n",
    "\n",
    "# f8 = open('gaze_ratio_lefteye_UD.txt', 'w')\n",
    "# f9 = open('gaze_ratio_righteye_UD.txt', 'w')\n",
    "# f10 = open('net_gaze_ratio_UD.txt', 'w')\n",
    "\n",
    "present_time = datetime.now()\n",
    "print( present_time )\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()  # to detect face\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # to detect points on face (landmarks)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "def middlepoint(n1, n2):\n",
    "    return int((n1.x + n2.x) / 2), int((n1.y + n2.y) / 2)\n",
    "\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # Compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "\n",
    "    # Compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "\n",
    "    # Compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    # Return the eye aspect ratio\n",
    "    return ear\n",
    "def  blinking_ratio(eye_points, face_landmarks):\n",
    "    eye_left = (face_landmarks.part(eye_points[0]).x, face_landmarks.part(eye_points[0]).y)\n",
    "    eye_right = (face_landmarks.part(eye_points[3]).x, face_landmarks.part(eye_points[3]).y)\n",
    "    eye_top = middlepoint(face_landmarks.part(eye_points[1]), face_landmarks.part(eye_points[2]))\n",
    "    eye_bottom = middlepoint(face_landmarks.part(eye_points[5]), face_landmarks.part(eye_points[4]))\n",
    "    \n",
    "    hLine = cv2.line(frame, eye_left, eye_right, (0, 255, 0), 2)\n",
    "    vLine = cv2.line(frame, eye_top, eye_bottom, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.rectangle(frame, (eye_left[0] - 10, eye_bottom[1] - 20), (eye_right[0] + 10, eye_top[1] + 20),\n",
    "                  (0, 255, 255), 2)\n",
    "\n",
    "    hor_lenght = hypot((eye_left[0] - eye_right[0]), (eye_left[1] - eye_right[1]))\n",
    "    ver_lenght = hypot((eye_top[0] - eye_bottom[0]), (eye_bottom[1] - eye_top[1]))\n",
    "\n",
    "    ratio = ver_lenght / hor_lenght\n",
    "\n",
    "    return ratio\n",
    "\n",
    "\n",
    "def gaze_ratio_LR(eye_points, facial_landmarks):\n",
    "    eye_region = np.array([(facial_landmarks.part(eye_points[0]).x, facial_landmarks.part(eye_points[0]).y),\n",
    "                            (facial_landmarks.part(eye_points[1]).x, facial_landmarks.part(eye_points[1]).y),\n",
    "                            (facial_landmarks.part(eye_points[2]).x, facial_landmarks.part(eye_points[2]).y),\n",
    "                            (facial_landmarks.part(eye_points[3]).x, facial_landmarks.part(eye_points[3]).y),\n",
    "                            (facial_landmarks.part(eye_points[4]).x, facial_landmarks.part(eye_points[4]).y),\n",
    "                            (facial_landmarks.part(eye_points[5]).x, facial_landmarks.part(eye_points[5]).y)], np.int32)\n",
    "\n",
    "    # SELECTING ONLY THE EYE FROM FACE\n",
    "    h, w, _ = frame.shape\n",
    "    mask = np.zeros((h, w), np.uint8)  # creating a black screen\n",
    "    cv2.polylines(mask, [eye_region], True, 255, 2)\n",
    "    cv2.fillPoly(mask, [eye_region], 255)  # filling the eye polygon with white color\n",
    "    left_eye = cv2.bitwise_and(gray, gray, mask=mask)  # need to see what it does\n",
    "\n",
    "    min_x = np.min(eye_region[:, 0])\n",
    "    max_x = np.max(eye_region[:, 0])\n",
    "    min_y = np.min(eye_region[:, 1])\n",
    "    max_y = np.max(eye_region[:, 1])\n",
    "\n",
    "    eye = frame[min_y: max_y, min_x: max_x]  # selecting the rectangular region with eye only\n",
    "    gray_eye = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)  # making gray scale\n",
    "    _, threshold_eye = cv2.threshold(gray_eye, 70, 255, cv2.THRESH_BINARY)  # creating a threshold\n",
    "\n",
    "    h, w = threshold_eye.shape\n",
    "    left_Threshold = threshold_eye[0:h, 0:int(w / 2)]  # left part of threshold_eye window\n",
    "    left_White = cv2.countNonZero(left_Threshold)  # zero mean black so non zero mean white\n",
    "\n",
    "    right_Threshold = threshold_eye[0:h, int(w / 2):w]  # right part of threshold_eye window\n",
    "    right_White = cv2.countNonZero(right_Threshold)\n",
    "    if left_White == 0:\n",
    "        gaze_ratio = 1\n",
    "    elif right_White == 0:\n",
    "        gaze_ratio = 3\n",
    "    else:\n",
    "        gaze_ratio = left_White / right_White\n",
    "    return gaze_ratio\n",
    "\n",
    "\n",
    "def gaze_ratio_UD(eye_points, facial_landmarks):\n",
    "    eye_region = np.array([(facial_landmarks.part(eye_points[0]).x, facial_landmarks.part(eye_points[0]).y),\n",
    "                           (facial_landmarks.part(eye_points[1]).x, facial_landmarks.part(eye_points[1]).y),\n",
    "                           (facial_landmarks.part(eye_points[2]).x, facial_landmarks.part(eye_points[2]).y),\n",
    "                           (facial_landmarks.part(eye_points[3]).x, facial_landmarks.part(eye_points[3]).y),\n",
    "                           (facial_landmarks.part(eye_points[4]).x, facial_landmarks.part(eye_points[4]).y),\n",
    "                           (facial_landmarks.part(eye_points[5]).x, facial_landmarks.part(eye_points[5]).y)], np.int32)\n",
    "\n",
    "    # SELECTING ONLY THE EYE FROM FACE\n",
    "    h, w, _ = frame.shape\n",
    "    mask = np.zeros((h, w), np.uint8)  # creating a black screen\n",
    "    cv2.polylines(mask, [eye_region], True, 255, 2)\n",
    "    cv2.fillPoly(mask, [eye_region], 255)  # filling the eye polygon with white color\n",
    "    left_eye = cv2.bitwise_and(gray, gray, mask=mask)  # need to see what it does\n",
    "\n",
    "    min_x = np.min(eye_region[:, 0])\n",
    "    max_x = np.max(eye_region[:, 0])\n",
    "    min_y = np.min(eye_region[:, 1])\n",
    "    max_y = np.max(eye_region[:, 1])\n",
    "\n",
    "    eye = frame[min_y: max_y, min_x: max_x]  # selecting the rectangular region with eye only\n",
    "    gray_eye = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)  # making gray scale\n",
    "    _, threshold_eye = cv2.threshold(gray_eye, 70, 255, cv2.THRESH_BINARY)  # creating a threshold dont know exactly what it mean\n",
    "    h, w = threshold_eye.shape\n",
    "    down_Threshold = threshold_eye[0:int(h/2), 0:w]  # bottom part of threshold_eye window\n",
    "    down_White = cv2.countNonZero(down_Threshold)  # zero mean black non zero mean white\n",
    "\n",
    "    up_Threshold = threshold_eye[int(h/2):h, 0:w]  # upper part of threshold_eye window\n",
    "    up_White = cv2.countNonZero(up_Threshold)\n",
    "    \n",
    "    if up_White == 0:\n",
    "        gaze_ratio = 0.00001\n",
    "    elif down_White == 0:\n",
    "        gaze_ratio = 30000\n",
    "    else:\n",
    "        gaze_ratio = up_White / down_White\n",
    "    return gaze_ratio\n",
    "\n",
    "\n",
    "def eye_movement_detection_UD(avg_blink_ratio):\n",
    "\n",
    "    if avg_blink_ratio>= 1.4 and avg_blink_ratio<= 3: \n",
    "        return \"Down\"\n",
    "    elif avg_blink_ratio> 3 and avg_blink_ratio<=4:\n",
    "        return \"Center\"\n",
    "    else:\n",
    "        return \"Up\"\n",
    "\n",
    "\n",
    "while True: \n",
    "    frame_counter += 1\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime \n",
    "    \n",
    "    #loop over all the face detections and apply the predictor \n",
    "    for face in faces: \n",
    "\n",
    "        face_x, face_y = face.left(), face.top()\n",
    "        face_x1, face_y1 = face.right(), face.bottom()\n",
    "        cv2.rectangle(frame, (face_x, face_y), (face_x1, face_y1), (0, 0, 255), 2)\n",
    "        landmarks = predictor(gray, face)  # the points on the face\n",
    "\n",
    "    # BLINK DETECTION\n",
    "    \n",
    "        right_ratio = blinking_ratio([36, 37, 38, 39, 40, 41], landmarks)\n",
    "        left_ratio = blinking_ratio([42, 43, 44, 45, 46, 47], landmarks)\n",
    "        net_blink_ratio = (right_ratio + left_ratio)/2.0\n",
    "        \n",
    "        \n",
    "        ###blinking datas       \n",
    "#         print(   dt.datetime.now().strftime('%H:%M:%S.%f'), file=f1)\n",
    "#         print( right_ratio , file=f2)\n",
    "#         print( left_ratio , file=f3)        \n",
    "#         print( net_blink_ratio , file=f4)                   \n",
    "        \n",
    "        if net_blink_ratio >= 5.7:\n",
    "            \n",
    "            Scroll = not Scroll\n",
    "            if not Scroll:\n",
    "                cv2.putText(frame, \"Scroll Enabled\", (250, 50), font, 1, (255, 0, 0), 3)                \n",
    "            if Scroll:\n",
    "                cv2.putText(frame, \"Scroll Disabled\", (250, 50), font, 1, (255, 0, 0), 3)\n",
    "\n",
    "            \n",
    "        elif net_blink_ratio < 0.2:\n",
    "            cv2.putText(frame, \"Blink\", (250, 50), font, 1, (255, 0, 0), 3)\n",
    "            pyautogui.click()               \n",
    "\n",
    "    # GAZE DETECTION\n",
    "        gaze_ratio_lefteye_LR = gaze_ratio_LR([42, 43, 44, 45, 46, 47], landmarks)\n",
    "        gaze_ratio_lefteye_UD = gaze_ratio_UD([42, 43, 44, 45, 46, 47], landmarks)\n",
    "        gaze_ratio_righteye_LR = gaze_ratio_LR([36, 37, 38, 39, 40, 41], landmarks)\n",
    "        gaze_ratio_righteye_UD = gaze_ratio_UD([36, 37, 38, 39, 40, 41], landmarks)\n",
    "\n",
    "        net_gaze_ratio_LR = (gaze_ratio_lefteye_LR + gaze_ratio_righteye_LR)/2.0\n",
    "        net_gaze_ratio_UD = (gaze_ratio_lefteye_UD + gaze_ratio_righteye_UD)/2.0\n",
    "        \n",
    "        \n",
    "#         print( gaze_ratio_lefteye_LR, file=f5)\n",
    "#         print( gaze_ratio_righteye_LR , file=f6)\n",
    "#         print( net_gaze_ratio_LR , file=f7)        \n",
    "            \n",
    "            \n",
    "#         print( gaze_ratio_lefteye_UD, file=f8)\n",
    "#         print( gaze_ratio_righteye_UD, file=f9)\n",
    "#         print(   net_gaze_ratio_UD , file=f10)  \n",
    "              \n",
    "        \n",
    "\n",
    "        if net_gaze_ratio_LR <= 0.8:\n",
    "            cv2.putText(frame, \"Gaze: Left\", (400,50), font, 1, (0, 0, 255), 2)\n",
    "        elif net_gaze_ratio_LR > 0.8 and net_gaze_ratio_LR <= 1.1:\n",
    "            cv2.putText(frame, \"CENTER\", (400, 50), font, 1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Gaze: Right\", (400, 50), font, 1, (0, 0, 255), 2)\n",
    "\n",
    "        if net_gaze_ratio_UD >= 0 and net_gaze_ratio_UD <= 3:\n",
    "            cv2.putText(frame, \"Gaze: Down\", (40, 50), font, 1, (0, 0, 255), 2)\n",
    "        elif net_gaze_ratio_UD > 3 and net_gaze_ratio_UD <= 4:\n",
    "            cv2.putText(frame, \"CENTER\", (40, 50), font, 1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Gaze: Up\", (40, 50), font, 1, (0, 0, 255), 2)\n",
    "\n",
    "        if eye_movement_detectection_LR(net_gaze_ratio_LR) == \"Right\":\n",
    "            pyautogui.move(20, 0)\n",
    "        if eye_movement_detectection_LR(net_gaze_ratio_LR) == \"Left\":\n",
    "            pyautogui.move(-20, 0)\n",
    "\n",
    "        if eye_movement_detection_UD(net_gaze_ratio_UD) == \"Up\":\n",
    "            pyautogui.move(0, 7)\n",
    "            if Scroll:\n",
    "                pyautogui.scroll(40)\n",
    "        if eye_movement_detection_UD(net_gaze_ratio_UD) == \"Down\":\n",
    "            pyautogui.move(0, -7)\n",
    "            if Scroll:\n",
    "                pyautogui.scroll(-40)\n",
    "                 \n",
    "              \n",
    "         # calculating the frame rate\n",
    "        Sec = time.time() - start_time  \n",
    "        FPS = frame_counter/Sec \n",
    "        #cv2.putText(frame, f'FPS:{int(FPS)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"FINAL\",frame)\n",
    "\n",
    "    # if q is pressed on keyboard: quit\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
